{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "568b7199",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras as keras\n",
    "from tensorflow.keras import layers, models, optimizers, metrics\n",
    "tf.config.optimizer.set_jit(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "68951451",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.ndimage import convolve\n",
    "\n",
    "class Connect4Game(object):\n",
    "  def __init__(self):\n",
    "    self.board = np.zeros((6, 7)).astype(np.int8)\n",
    "    self.tops = np.zeros(7).astype(np.int8)\n",
    "    self.moves_played = 0\n",
    "    self.pieces = {1: \"üî¥\",\n",
    "                   0: \"‚¨õ\",\n",
    "                   -1:\"üü°\"}\n",
    "  def render(self):\n",
    "    for row in reversed(range(6)):\n",
    "      print(''.join([self.pieces[i] for i in self.board[row].astype(np.int)]))\n",
    "    print(\"1Ô∏è‚É£2Ô∏è‚É£3Ô∏è‚É£4Ô∏è‚É£5Ô∏è‚É£6Ô∏è‚É£7Ô∏è‚É£\")\n",
    "  def reset(self):\n",
    "    self.board *= 0\n",
    "    self.tops *= 0\n",
    "    self.moves_played = 0\n",
    "  def play(self, col, color):\n",
    "    self.board[int(self.tops[col])][col] = color\n",
    "    self.tops[col] += 1\n",
    "    self.moves_played += 1\n",
    "  def result(self):\n",
    "    \"\"\" Returns 0 if it's a tie; returns None if the game is not over; returns -1 if player -1 wins, and 1 if player 1 wins.\"\"\"\n",
    "    if self.moves_played == 42: return 0\n",
    "    kernel_row = [[1, 1, 1, 1]]\n",
    "    kernel_col = [[1],\n",
    "                  [1],\n",
    "                  [1],\n",
    "                  [1]]\n",
    "    kernel_dia = [[1, 0, 0, 0],\n",
    "                  [0, 1, 0, 0],\n",
    "                  [0, 0, 1, 0],\n",
    "                  [0, 0, 0, 1]]\n",
    "    kernel_dia2 = [[0, 0, 0, 1],\n",
    "                  [0, 0, 1, 0],\n",
    "                  [0, 1, 0, 0],\n",
    "                  [1, 0, 0, 0]]\n",
    "    for kernel in [np.array(kernel_row).astype(np.int8), np.array(kernel_col).astype(np.int8), np.array(kernel_dia).astype(np.int8), np.array(kernel_dia2).astype(np.int8)]:\n",
    "      check = convolve(self.board, kernel, mode='constant')\n",
    "      #print(check)\n",
    "      if (check == 4).any(): return 1\n",
    "      if (check == -4).any(): return -1\n",
    "    return None "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "07d911ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from collections import defaultdict\n",
    "import random\n",
    "import time, tqdm\n",
    "\n",
    "def softmax(x, temperature=1):\n",
    "    return np.exp(x/temperature)/sum(np.exp(x/temperature))\n",
    "\n",
    "class A0(object):\n",
    "    def __init__(self, name, model_complexity = 2, n_simulations = 64, model = None):\n",
    "        # Hyperparameters\n",
    "        self.n_simulations = n_simulations # Keep it simple\n",
    "        self.c = 1 # weight for exploration\n",
    "        self.n_parallel = os.cpu_count()\n",
    "        \n",
    "        # Basic\n",
    "        self.name = name\n",
    "        self.simulator = Connect4Game() # Would be different if this were muzero\n",
    "        self.model_complexity = model_complexity # 1+\n",
    "        if model == None:\n",
    "            self.model = self.create_model(conv_layers = self.model_complexity, describe = True)\n",
    "        else:\n",
    "            print(\"Loading model from memory.\")\n",
    "            self.model = model\n",
    "        \n",
    "        # Monte Carlo Tree Search stuff\n",
    "        self.visited = set()\n",
    "        self.Q, self.P, self.N = defaultdict(lambda: np.zeros(7).astype(np.float32)), {}, defaultdict(lambda: np.zeros(7).astype(np.uint8))\n",
    "\n",
    "        \n",
    "    def create_model(self, conv_layers = 2,describe = False):\n",
    "        in_ = layers.Input((6, 7, 1))\n",
    "        X = layers.Conv2D(32, (4,4), activation = 'relu', padding = \"same\")(in_)\n",
    "        for i in range(conv_layers-1):\n",
    "            X_skip = layers.Conv2D(32, (3,3), activation = 'relu', padding = \"same\")(X)\n",
    "            X_skip = layers.BatchNormalization()(X_skip)\n",
    "            X_skip = layers.Conv2D(32, (2,2), activation = 'relu', padding = \"same\")(X_skip)\n",
    "            X_skip = layers.BatchNormalization()(X_skip)\n",
    "            X = layers.BatchNormalization()(X)\n",
    "            X = layers.Add()([X_skip, X])\n",
    "        X = layers.Conv2D(32, (2,2), activation = 'relu')(X)\n",
    "        X = layers.BatchNormalization()(X)\n",
    "        #X = layers.GlobalAveragePooling2D()(X)\n",
    "        X = layers.Flatten()(X)\n",
    "        #P = layers.Dense(32, activation = 'relu')(X)\n",
    "        P = layers.Dense(7, activation = 'softmax', name = \"P_head\")(X) # Check the activations here\n",
    "        Q = layers.Dense(8, activation = 'relu')(X)\n",
    "        Q = layers.Dense(1, activation = 'tanh', name = \"Q_head\")(Q)\n",
    "        model = models.Model(in_, [P, Q])\n",
    "        model.compile(optimizer=optimizers.Adam(0.001), loss={'P_head': \"binary_crossentropy\", 'Q_head': \"mse\"})\n",
    "        \n",
    "        if describe: \n",
    "            tf.keras.utils.plot_model(\n",
    "                model,\n",
    "                to_file=\"model.png\",\n",
    "                show_shapes=True,\n",
    "                show_dtype=True,\n",
    "                show_layer_names=True,\n",
    "                rankdir=\"TB\",\n",
    "                expand_nested=False,\n",
    "                dpi=120,\n",
    "                layer_range=None,\n",
    "                show_layer_activations=True,\n",
    "            )\n",
    "            img = Image.open(\"model.png\")\n",
    "            wpercent = (750/float(img.size[0]))\n",
    "            hsize = int((float(img.size[1])*float(wpercent)))\n",
    "            img = img.resize((750,hsize), Image.Resampling.LANCZOS)\n",
    "            display(img)\n",
    "            \n",
    "            trainableParams = np.sum([np.prod(v.get_shape()) for v in model.trainable_weights])\n",
    "            nonTrainableParams = np.sum([np.prod(v.get_shape()) for v in model.non_trainable_weights])\n",
    "            totalParams = trainableParams + nonTrainableParams\n",
    "\n",
    "            print(\"Trainable parameters:\", trainableParams)\n",
    "            print(\"Untrainable parameters:\",nonTrainableParams)\n",
    "            print(\"Total parameters:\",totalParams)\n",
    "        return model        \n",
    "    \n",
    "    def MCTS(self, game, turn):\n",
    "        self.simulator.board = game.board\n",
    "        self.simulator.tops = game.tops\n",
    "        self.simulator.moves_played = game.moves_played\n",
    "        \n",
    "        if self.simulator.result() != None: return -self.simulator.result() * turn # It's over, Anakin!\n",
    "        # TODO: CHECK HOW THE ABOVE INTERACTS WITH THE SIGN SWITCHING\n",
    "        s = self.simulator.board * turn\n",
    "            \n",
    "        if s.tobytes() not in self.visited:\n",
    "            \"\"\"\n",
    "            Let's be very clear about this. The model is NOT TURN AGNOSTIC: the board is flipped to encode the active \n",
    "            player's pieces as 1 at all times.\n",
    "            \n",
    "            The Q head of the model predicts the quality of the board between 1 and -1 (thus the tanh activation).\n",
    "            Positions more favored for the current player have qualities approaching 1; positions favored for the\n",
    "            adversary have qualities approaching -1. \n",
    "            \n",
    "            The P head of the model predicts how promising each action is for the current player. Note that\n",
    "            keeping the model turn agnostic would necessitate passing in the current turn to the P head (as to denote\n",
    "            the player whose moves' potentials would have to be calculated) and lay an unnecessary burden upon the P network.\n",
    "            \n",
    "            Also, the tanh activation and (1, -1) encoding is so that multiplying v by -1 yields v for the opponent (convenient!)\n",
    "            \"\"\"\n",
    "            self.visited.add(s.tobytes())\n",
    "            # self.P[s.tobytes()], v = np.ones(7)/7, 0 #DEBUG ONLY\n",
    "            \n",
    "            p_, v_ = self.model(s[np.newaxis, :, :, np.newaxis]) # Why not save v as the starting value for Q[s][a], you may ask?\n",
    "                        # Because that injects bias into the MCTS, and we want to keep the \"pure\" MCTS output to boost the model.\n",
    "                        # Essentially, we want to minimize the potential for feedback loops as much as possible (model predicting\n",
    "                        # high initial quality, MCTS outputting high initial quality and prodicing biased games, etc).\n",
    "            self.P[s.tobytes()] = p_[0]\n",
    "            v = v_[0]\n",
    "                        \n",
    "            return -v # Invert the quality. Let's imagine it's move 0 (the board state in the real game). On MCTS call 1, \n",
    "                        # the function returns -v (v = network at-a-glance), which is fine, since we don't care about the output \n",
    "                        # (only used to calculate N). On call 2, the function goes to the next move and evaluates the board for \n",
    "                        # the opponent (let's dub this o.) -o, or v, gets returned, and then v is used to update N and Q, before\n",
    "                        # -v being returned to the main function. Notice that the value used to update N is always +v.\n",
    "        \n",
    "        legal_moves = [i for i in range(7) if game.tops[i] != 6]\n",
    "        \n",
    "        s = s.tobytes() # make it hashable\n",
    "        best_a = random.choice(legal_moves) # inject randomness instead of using [0] to avoid making any one move extra prevalent in the case of a tie\n",
    "        best_u = -float(\"inf\")\n",
    "        u_s, a_s = [],[]\n",
    "        for a in legal_moves: # legal moves\n",
    "            u = self.Q[s][a] + self.c * self.P[s][a] * np.sqrt(np.sum(self.N[s]))/(1+self.N[s][a]) # upper confidence bound (UCB) \n",
    "            u_s.append(u)\n",
    "            if u > best_u: \n",
    "                best_u = u\n",
    "                \n",
    "        a = random.choice([legal_moves[index] for index, u in enumerate(u_s) if u == best_u]) \n",
    "        \n",
    "        self.simulator.play(a, turn)\n",
    "        v = self.MCTS(self.simulator, -turn)\n",
    "        \n",
    "        self.Q[s][a] = (self.N[s][a] * self.Q[s][a] + v) / (self.N[s][a] + 1) # Recalculate Q as the average quality\n",
    "        self.N[s][a] += 1\n",
    "        \n",
    "        return -v\n",
    "    \n",
    "    def play_episode(self, temperature, debug = False):        \n",
    "        game = Connect4Game()\n",
    "        turn = 1\n",
    "        \n",
    "        # Data\n",
    "        p1_states, pneg1_states = [], []\n",
    "        p1_policies, pneg1_policies = [], []\n",
    "        \n",
    "        if debug: times = []\n",
    "        while (game.result() == None):\n",
    "            \n",
    "            for i in range(self.n_simulations):\n",
    "                if debug: starttime = time.time()\n",
    "                    \n",
    "                copy_game = Connect4Game()\n",
    "                # Pass by copy (we don't want the internal MCTS to modify the outer game)\n",
    "                copy_game.board = game.board.copy()\n",
    "                copy_game.tops = game.tops.copy()\n",
    "                copy_game.moves_played = game.moves_played # integer\n",
    "                self.MCTS(copy_game, turn)\n",
    "        \n",
    "                if debug: times.append(time.time() - starttime)\n",
    "                        \n",
    "            s = (game.board * turn).tobytes()\n",
    "            assert(np.sum(self.N[s]) == self.n_simulations-1)\n",
    "            \n",
    "            probs = np.log(self.N[s]+0.01)\n",
    "            probs = softmax(probs, temperature = temperature)\n",
    "            probs = np.array([probs[a] if game.tops[a] != 6 else 0 for a in range(7)])\n",
    "                        \n",
    "            self.visited.clear() # Reset tree\n",
    "            if debug: \n",
    "              print(\"Turn: \", turn)\n",
    "              game.render()\n",
    "              print(self.N[s])\n",
    "            self.N.clear()\n",
    "            self.Q.clear()\n",
    "            self.P.clear()\n",
    "            \n",
    "            probs *= (1/np.sum(probs))\n",
    "            if debug: print(probs)\n",
    "            \n",
    "            # Double check if the agents are supposed to move based on their MCTS qualities or their predicted policy.\n",
    "                        \n",
    "            # Also double check if the policy network is supposed to be trained on the valid policy weights (softmaxed) \n",
    "            # as I do here (is it too burdensome to train the policy network using only the valid part of the MCTS policy distribution?)\n",
    "            \n",
    "            assert turn == 1 or turn == -1\n",
    "            if turn == 1:\n",
    "                p1_policies.append(probs)\n",
    "                p1_states.append((game.board * turn)[:,:,np.newaxis])\n",
    "            if turn == -1:\n",
    "                pneg1_policies.append(probs)\n",
    "                pneg1_states.append((game.board * turn)[:,:,np.newaxis])\n",
    "            action = np.random.choice(range(0, 7), p = probs)\n",
    "            game.play(action, turn)\n",
    "\n",
    "            turn *= -1\n",
    "        \n",
    "        states = p1_states + pneg1_states # Label all qualities of the states from the pov of player 1 as 1 if p1 wins, -1 otherwise\n",
    "        Q_target = [game.result()]*len(p1_states) + [-game.result()]*len(pneg1_states) # Label all qualities of the states from the pov of player -1 as -1 if p1 wins, 1 otherwise\n",
    "        P_target = p1_policies + pneg1_policies # Match up with the states and Q target\n",
    "        if debug: print(\"Average MCTS time:\", sum(times) / len(times))\n",
    "            \n",
    "        return states, P_target, Q_target\n",
    "    \n",
    "    def fit(self, data, batch_size, epochs):\n",
    "        \n",
    "        states, P_target, Q_target = data\n",
    "        \n",
    "        self.new = self.create_model(conv_layers = self.model_complexity, describe = False)\n",
    "        self.new.set_weights(self.model.get_weights())\n",
    "        self.new.fit(x = np.array(states), y = {\"Q_head\": np.array(Q_target), \"P_head\": np.array(P_target)}, batch_size = batch_size, epochs = epochs, shuffle = True)\n",
    "        return self.new\n",
    "    \n",
    "    def make_move(self, game, turn, temperature = 0.1, n_simulations = None, display = True):\n",
    "        if n_simulations == None: simulations = self.n_simulations\n",
    "        else: simulations = n_simulations\n",
    "        for i in range(simulations):\n",
    "            copy_game = Connect4Game()\n",
    "            # Pass by copy (we don't want the internal MCTS to modify the outer game)\n",
    "            copy_game.board = game.board.copy()\n",
    "            copy_game.tops = game.tops.copy()\n",
    "            copy_game.moves_played = game.moves_played # integer\n",
    "            v = self.MCTS(copy_game, turn)\n",
    "        s = (game.board * turn).tobytes()\n",
    "\n",
    "        assert(np.sum(self.N[s]) == simulations-1)\n",
    "\n",
    "        probs = np.log(self.N[s]+0.01)\n",
    "        probs = softmax(probs, temperature = temperature)\n",
    "        probs = np.array([probs[a] if game.tops[a] != 6 else 0 for a in range(7)])\n",
    "        probs *= (1/np.sum(probs))\n",
    "\n",
    "        action = np.random.choice(range(0, 7), p = probs)\n",
    "        if display:\n",
    "            print(\"Turn: \", turn)\n",
    "            p_, v_ = self.model((game.board * turn)[np.newaxis, :, :, np.newaxis])\n",
    "            np.set_printoptions(precision=3, suppress=True)\n",
    "            \n",
    "            print(\"Heuristics:\\nMove probabilities:\",p_[0].numpy())\n",
    "            print(\"Est. Score (1 = win, -1 = loss):\",v_[0].numpy()[0])\n",
    "            print(\"On second thought:\\nMove probabilities:\",probs)\n",
    "            print(\"Est. Score (1 = win, -1 = loss):\",v.numpy()[0] if type(v) != int else v)\n",
    "            print(\"# explored moves for each position: \", self.N[s])\n",
    "\n",
    "        self.visited.clear() # Reset tree\n",
    "        self.N.clear()\n",
    "        self.Q.clear()\n",
    "        self.P.clear()\n",
    "        \n",
    "        return action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0932ca7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class A0_nodepth:\n",
    "    def __init__(self, name, model_complexity = 2, model = None):\n",
    "            # Basic\n",
    "            self.name = name\n",
    "            self.simulator = Connect4Game() # Would be different if this were muzero\n",
    "            self.model_complexity = model_complexity # 1+\n",
    "            if model == None:\n",
    "                self.model = self.create_model(conv_layers = self.model_complexity, describe = True)\n",
    "            else:\n",
    "                print(\"Loading model from memory.\")\n",
    "                self.model = model\n",
    "                \n",
    "    def make_move(self, game, turn, temperature = 0.8, n_simulations = None, display = False):\n",
    "        p_, v_ = self.model((game.board * turn)[np.newaxis, :, :, np.newaxis])\n",
    "        probs = np.log(p_[0])\n",
    "        probs = softmax(probs, temperature = temperature)\n",
    "        probs = np.array([probs[a] if game.tops[a] != 6 else 0 for a in range(7)])\n",
    "        probs *= (1/np.sum(probs))\n",
    "\n",
    "        action = np.random.choice(range(0, 7), p = probs)\n",
    "        if display:\n",
    "            print(\"Turn: \", turn)\n",
    "            print(\"Heuristics:\",p_[0].numpy(), v_[0].numpy())\n",
    "        return action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "dd095e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate\n",
    "import random\n",
    "\n",
    "class Ladder(object):\n",
    "    def __init__(self):\n",
    "        self.game = Connect4Game()\n",
    "    def play_match(self, player_1, player_neg1, render = False):\n",
    "        turn = 1\n",
    "        self.game.reset()\n",
    "        while (self.game.result() == None):\n",
    "            if render: self.game.render()\n",
    "            \n",
    "            if turn == 1:\n",
    "                action = player_1.make_move(self.game, turn)\n",
    "            if turn == -1:\n",
    "                action = player_neg1.make_move(self.game, turn)\n",
    "            self.game.play(action, turn)\n",
    "            \n",
    "            turn *= -1\n",
    "\n",
    "            \n",
    "        result = self.game.result()\n",
    "        if render: \n",
    "            self.game.render()\n",
    "            print(\"GAME OVER!\")\n",
    "            if result == 1: print(\"Red player wins!\")\n",
    "            if result == -1: print(\"Yellow player wins!\")\n",
    "            if result == 0: print(\"It's a tie!\")\n",
    "\n",
    "        self.game.reset()\n",
    "        return result\n",
    "    \n",
    "    def play_tournament(self, players, NUM_MATCHES = 1000, K = 16, onesd = 400):\n",
    "        MMR = {}\n",
    "        for player in players:\n",
    "            MMR[player.name] = 1000\n",
    "        for match in tqdm.trange(NUM_MATCHES):\n",
    "            p1, p_neg1 = random.sample(players, 2)\n",
    "            result = self.play_match(p1, p_neg1)\n",
    "            \n",
    "            SA = (result + 1) / 2 # A scores 1 point if win, 0 points if loss.\n",
    "            SB = (-result + 1) / 2 # B scores 1 point if win, -1 points if loss.\n",
    "            # Both score 0.5 points if tie.\n",
    "            EA = 1 / (1 + 10**((MMR[p_neg1.name] - MMR[p1.name]) / onesd))\n",
    "            EB = 1 / (1 + 10**((MMR[p1.name] - MMR[p_neg1.name]) / onesd))\n",
    "            \n",
    "            MMR[p1.name] = MMR[p1.name] + K * (SA - EA)\n",
    "            MMR[p_neg1.name] = MMR[p_neg1.name] + K * (SB - EB)\n",
    "        new_MMR = {}\n",
    "        for key in MMR:\n",
    "            new_MMR[key] = 1000 + MMR[key] - MMR[\"Random\"]\n",
    "        return new_MMR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c742b894",
   "metadata": {},
   "outputs": [],
   "source": [
    "class human_player():\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def make_move(self, game, turn):\n",
    "        legal_moves = [i for i in range(7) if game.tops[i] != 6]\n",
    "        while True:\n",
    "            print(\"Your turn:\",turn)\n",
    "            game.render()\n",
    "            move = int(input())-1\n",
    "            if move in legal_moves: break\n",
    "            else: print(\"That's not a legal move.\")\n",
    "        return move"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "5d48d55b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.load_model(\"Remote/v3_Boosted.h5\", compile = False)\n",
    "model.compile(optimizer=optimizers.Adam(0.001), loss={'P_head': \"binary_crossentropy\", 'Q_head': \"mse\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "cb386d27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from memory.\n"
     ]
    }
   ],
   "source": [
    "agent = A0_nodepth(\"heuristic\", 6, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "1fb4fc5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from memory.\n",
      "Loading model from memory.\n"
     ]
    }
   ],
   "source": [
    "agent = A0(\"agent\", 12, 64, model)\n",
    "agent_2 = A0(\"adversary\", 12, 84, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ef53a63a",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.c = 5\n",
    "agent_2.c = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "bfc9f0b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ladder = Ladder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "1a7709f4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\william\\AppData\\Local\\Temp\\ipykernel_7368\\1414013612.py:13: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  print(''.join([self.pieces[i] for i in self.board[row].astype(np.int)]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚¨õ‚¨õ‚¨õ‚¨õ‚¨õ‚¨õ‚¨õ\n",
      "‚¨õ‚¨õ‚¨õ‚¨õ‚¨õ‚¨õ‚¨õ\n",
      "‚¨õ‚¨õ‚¨õ‚¨õ‚¨õ‚¨õ‚¨õ\n",
      "‚¨õ‚¨õ‚¨õ‚¨õ‚¨õ‚¨õ‚¨õ\n",
      "‚¨õ‚¨õ‚¨õ‚¨õ‚¨õ‚¨õ‚¨õ\n",
      "‚¨õ‚¨õ‚¨õ‚¨õ‚¨õ‚¨õ‚¨õ\n",
      "1Ô∏è‚É£2Ô∏è‚É£3Ô∏è‚É£4Ô∏è‚É£5Ô∏è‚É£6Ô∏è‚É£7Ô∏è‚É£\n",
      "Turn:  1\n",
      "Heuristics:\n",
      "Move probabilities: [0.003 0.004 0.004 0.973 0.005 0.005 0.006]\n",
      "Est. Score (1 = win, -1 = loss): 0.065749936\n",
      "On second thought:\n",
      "Move probabilities: [0. 0. 0. 1. 0. 0. 0.]\n",
      "Est. Score (1 = win, -1 = loss): 0.24134068\n",
      "# explored moves for each position:  [ 0  0  1 62  0  0  0]\n",
      "‚¨õ‚¨õ‚¨õ‚¨õ‚¨õ‚¨õ‚¨õ\n",
      "‚¨õ‚¨õ‚¨õ‚¨õ‚¨õ‚¨õ‚¨õ\n",
      "‚¨õ‚¨õ‚¨õ‚¨õ‚¨õ‚¨õ‚¨õ\n",
      "‚¨õ‚¨õ‚¨õ‚¨õ‚¨õ‚¨õ‚¨õ\n",
      "‚¨õ‚¨õ‚¨õ‚¨õ‚¨õ‚¨õ‚¨õ\n",
      "‚¨õ‚¨õ‚¨õüî¥‚¨õ‚¨õ‚¨õ\n",
      "1Ô∏è‚É£2Ô∏è‚É£3Ô∏è‚É£4Ô∏è‚É£5Ô∏è‚É£6Ô∏è‚É£7Ô∏è‚É£\n",
      "Turn:  -1\n",
      "Heuristics:\n",
      "Move probabilities: [0.004 0.008 0.007 0.967 0.003 0.004 0.006]\n",
      "Est. Score (1 = win, -1 = loss): -0.19095679\n",
      "On second thought:\n",
      "Move probabilities: [0. 0. 0. 1. 0. 0. 0.]\n",
      "Est. Score (1 = win, -1 = loss): -0.016984036\n",
      "# explored moves for each position:  [ 0  1  0 82  0  0  0]\n",
      "‚¨õ‚¨õ‚¨õ‚¨õ‚¨õ‚¨õ‚¨õ\n",
      "‚¨õ‚¨õ‚¨õ‚¨õ‚¨õ‚¨õ‚¨õ\n",
      "‚¨õ‚¨õ‚¨õ‚¨õ‚¨õ‚¨õ‚¨õ\n",
      "‚¨õ‚¨õ‚¨õ‚¨õ‚¨õ‚¨õ‚¨õ\n",
      "‚¨õ‚¨õ‚¨õüü°‚¨õ‚¨õ‚¨õ\n",
      "‚¨õ‚¨õ‚¨õüî¥‚¨õ‚¨õ‚¨õ\n",
      "1Ô∏è‚É£2Ô∏è‚É£3Ô∏è‚É£4Ô∏è‚É£5Ô∏è‚É£6Ô∏è‚É£7Ô∏è‚É£\n",
      "Turn:  1\n",
      "Heuristics:\n",
      "Move probabilities: [0.005 0.005 0.029 0.018 0.483 0.454 0.006]\n",
      "Est. Score (1 = win, -1 = loss): 0.06079538\n",
      "On second thought:\n",
      "Move probabilities: [0.    0.    0.    0.    0.091 0.909 0.   ]\n",
      "Est. Score (1 = win, -1 = loss): -0.065749936\n",
      "# explored moves for each position:  [ 0  0  1  1 27 34  0]\n",
      "‚¨õ‚¨õ‚¨õ‚¨õ‚¨õ‚¨õ‚¨õ\n",
      "‚¨õ‚¨õ‚¨õ‚¨õ‚¨õ‚¨õ‚¨õ\n",
      "‚¨õ‚¨õ‚¨õ‚¨õ‚¨õ‚¨õ‚¨õ\n",
      "‚¨õ‚¨õ‚¨õ‚¨õ‚¨õ‚¨õ‚¨õ\n",
      "‚¨õ‚¨õ‚¨õüü°‚¨õ‚¨õ‚¨õ\n",
      "‚¨õ‚¨õ‚¨õüî¥‚¨õüî¥‚¨õ\n",
      "1Ô∏è‚É£2Ô∏è‚É£3Ô∏è‚É£4Ô∏è‚É£5Ô∏è‚É£6Ô∏è‚É£7Ô∏è‚É£\n",
      "Turn:  -1\n",
      "Heuristics:\n",
      "Move probabilities: [0.008 0.008 0.023 0.033 0.722 0.009 0.196]\n",
      "Est. Score (1 = win, -1 = loss): -0.14289266\n",
      "On second thought:\n",
      "Move probabilities: [0. 0. 0. 0. 1. 0. 0.]\n",
      "Est. Score (1 = win, -1 = loss): 0.27078053\n",
      "# explored moves for each position:  [ 0  0  1  1 63  1 17]\n",
      "‚¨õ‚¨õ‚¨õ‚¨õ‚¨õ‚¨õ‚¨õ\n",
      "‚¨õ‚¨õ‚¨õ‚¨õ‚¨õ‚¨õ‚¨õ\n",
      "‚¨õ‚¨õ‚¨õ‚¨õ‚¨õ‚¨õ‚¨õ\n",
      "‚¨õ‚¨õ‚¨õ‚¨õ‚¨õ‚¨õ‚¨õ\n",
      "‚¨õ‚¨õ‚¨õüü°‚¨õ‚¨õ‚¨õ\n",
      "‚¨õ‚¨õ‚¨õüî¥üü°üî¥‚¨õ\n",
      "1Ô∏è‚É£2Ô∏è‚É£3Ô∏è‚É£4Ô∏è‚É£5Ô∏è‚É£6Ô∏è‚É£7Ô∏è‚É£\n",
      "Turn:  1\n",
      "Heuristics:\n",
      "Move probabilities: [0.001 0.005 0.001 0.986 0.003 0.002 0.002]\n",
      "Est. Score (1 = win, -1 = loss): 0.054285266\n",
      "On second thought:\n",
      "Move probabilities: [0. 0. 0. 1. 0. 0. 0.]\n",
      "Est. Score (1 = win, -1 = loss): -0.50716144\n",
      "# explored moves for each position:  [ 0  1  0 62  0  0  0]\n",
      "‚¨õ‚¨õ‚¨õ‚¨õ‚¨õ‚¨õ‚¨õ\n",
      "‚¨õ‚¨õ‚¨õ‚¨õ‚¨õ‚¨õ‚¨õ\n",
      "‚¨õ‚¨õ‚¨õ‚¨õ‚¨õ‚¨õ‚¨õ\n",
      "‚¨õ‚¨õ‚¨õüî¥‚¨õ‚¨õ‚¨õ\n",
      "‚¨õ‚¨õ‚¨õüü°‚¨õ‚¨õ‚¨õ\n",
      "‚¨õ‚¨õ‚¨õüî¥üü°üî¥‚¨õ\n",
      "1Ô∏è‚É£2Ô∏è‚É£3Ô∏è‚É£4Ô∏è‚É£5Ô∏è‚É£6Ô∏è‚É£7Ô∏è‚É£\n",
      "Turn:  -1\n",
      "Heuristics:\n",
      "Move probabilities: [0.012 0.03  0.017 0.715 0.026 0.182 0.017]\n",
      "Est. Score (1 = win, -1 = loss): -0.16343409\n",
      "On second thought:\n",
      "Move probabilities: [0. 0. 0. 1. 0. 0. 0.]\n",
      "Est. Score (1 = win, -1 = loss): 0.030191822\n",
      "# explored moves for each position:  [ 1  3  1 59  2 16  1]\n",
      "‚¨õ‚¨õ‚¨õ‚¨õ‚¨õ‚¨õ‚¨õ\n",
      "‚¨õ‚¨õ‚¨õ‚¨õ‚¨õ‚¨õ‚¨õ\n",
      "‚¨õ‚¨õ‚¨õüü°‚¨õ‚¨õ‚¨õ\n",
      "‚¨õ‚¨õ‚¨õüî¥‚¨õ‚¨õ‚¨õ\n",
      "‚¨õ‚¨õ‚¨õüü°‚¨õ‚¨õ‚¨õ\n",
      "‚¨õ‚¨õ‚¨õüî¥üü°üî¥‚¨õ\n",
      "1Ô∏è‚É£2Ô∏è‚É£3Ô∏è‚É£4Ô∏è‚É£5Ô∏è‚É£6Ô∏è‚É£7Ô∏è‚É£\n",
      "Turn:  1\n",
      "Heuristics:\n",
      "Move probabilities: [0.014 0.421 0.014 0.015 0.461 0.037 0.039]\n",
      "Est. Score (1 = win, -1 = loss): 0.065749936\n",
      "On second thought:\n",
      "Move probabilities: [0.    0.007 0.    0.    0.993 0.    0.   ]\n",
      "Est. Score (1 = win, -1 = loss): -0.43421307\n",
      "# explored moves for each position:  [ 0 22  1  0 36  2  2]\n",
      "‚¨õ‚¨õ‚¨õ‚¨õ‚¨õ‚¨õ‚¨õ\n",
      "‚¨õ‚¨õ‚¨õ‚¨õ‚¨õ‚¨õ‚¨õ\n",
      "‚¨õ‚¨õ‚¨õüü°‚¨õ‚¨õ‚¨õ\n",
      "‚¨õ‚¨õ‚¨õüî¥‚¨õ‚¨õ‚¨õ\n",
      "‚¨õ‚¨õ‚¨õüü°üî¥‚¨õ‚¨õ\n",
      "‚¨õ‚¨õ‚¨õüî¥üü°üî¥‚¨õ\n",
      "1Ô∏è‚É£2Ô∏è‚É£3Ô∏è‚É£4Ô∏è‚É£5Ô∏è‚É£6Ô∏è‚É£7Ô∏è‚É£\n",
      "Turn:  -1\n",
      "Heuristics:\n",
      "Move probabilities: [0.016 0.029 0.023 0.044 0.777 0.049 0.063]\n",
      "Est. Score (1 = win, -1 = loss): -0.23703961\n",
      "On second thought:\n",
      "Move probabilities: [0. 0. 0. 0. 1. 0. 0.]\n",
      "Est. Score (1 = win, -1 = loss): -0.4957307\n",
      "# explored moves for each position:  [ 1  2  1  3 69  3  4]\n",
      "‚¨õ‚¨õ‚¨õ‚¨õ‚¨õ‚¨õ‚¨õ\n",
      "‚¨õ‚¨õ‚¨õ‚¨õ‚¨õ‚¨õ‚¨õ\n",
      "‚¨õ‚¨õ‚¨õüü°‚¨õ‚¨õ‚¨õ\n",
      "‚¨õ‚¨õ‚¨õüî¥üü°‚¨õ‚¨õ\n",
      "‚¨õ‚¨õ‚¨õüü°üî¥‚¨õ‚¨õ\n",
      "‚¨õ‚¨õ‚¨õüî¥üü°üî¥‚¨õ\n",
      "1Ô∏è‚É£2Ô∏è‚É£3Ô∏è‚É£4Ô∏è‚É£5Ô∏è‚É£6Ô∏è‚É£7Ô∏è‚É£\n",
      "Turn:  1\n",
      "Heuristics:\n",
      "Move probabilities: [0.009 0.086 0.027 0.019 0.707 0.099 0.053]\n",
      "Est. Score (1 = win, -1 = loss): -0.010629164\n",
      "On second thought:\n",
      "Move probabilities: [0. 0. 0. 0. 1. 0. 0.]\n",
      "Est. Score (1 = win, -1 = loss): -0.051606037\n",
      "# explored moves for each position:  [ 1  3  1  1 51  3  3]\n",
      "‚¨õ‚¨õ‚¨õ‚¨õ‚¨õ‚¨õ‚¨õ\n",
      "‚¨õ‚¨õ‚¨õ‚¨õ‚¨õ‚¨õ‚¨õ\n",
      "‚¨õ‚¨õ‚¨õüü°üî¥‚¨õ‚¨õ\n",
      "‚¨õ‚¨õ‚¨õüî¥üü°‚¨õ‚¨õ\n",
      "‚¨õ‚¨õ‚¨õüü°üî¥‚¨õ‚¨õ\n",
      "‚¨õ‚¨õ‚¨õüî¥üü°üî¥‚¨õ\n",
      "1Ô∏è‚É£2Ô∏è‚É£3Ô∏è‚É£4Ô∏è‚É£5Ô∏è‚É£6Ô∏è‚É£7Ô∏è‚É£\n",
      "Turn:  -1\n",
      "Heuristics:\n",
      "Move probabilities: [0.045 0.064 0.047 0.042 0.054 0.459 0.289]\n",
      "Est. Score (1 = win, -1 = loss): -0.32121637\n",
      "On second thought:\n",
      "Move probabilities: [0.    0.    0.    0.    0.    0.998 0.002]\n",
      "Est. Score (1 = win, -1 = loss): 0.3632102\n",
      "# explored moves for each position:  [ 3  7  2  4  4 41 22]\n",
      "‚¨õ‚¨õ‚¨õ‚¨õ‚¨õ‚¨õ‚¨õ\n",
      "‚¨õ‚¨õ‚¨õ‚¨õ‚¨õ‚¨õ‚¨õ\n",
      "‚¨õ‚¨õ‚¨õüü°üî¥‚¨õ‚¨õ\n",
      "‚¨õ‚¨õ‚¨õüî¥üü°‚¨õ‚¨õ\n",
      "‚¨õ‚¨õ‚¨õüü°üî¥üü°‚¨õ\n",
      "‚¨õ‚¨õ‚¨õüî¥üü°üî¥‚¨õ\n",
      "1Ô∏è‚É£2Ô∏è‚É£3Ô∏è‚É£4Ô∏è‚É£5Ô∏è‚É£6Ô∏è‚É£7Ô∏è‚É£\n",
      "Turn:  1\n",
      "Heuristics:\n",
      "Move probabilities: [0.012 0.029 0.039 0.022 0.038 0.22  0.64 ]\n",
      "Est. Score (1 = win, -1 = loss): 0.08220405\n",
      "On second thought:\n",
      "Move probabilities: [0. 0. 0. 0. 0. 0. 1.]\n",
      "Est. Score (1 = win, -1 = loss): -0.5397\n",
      "# explored moves for each position:  [ 0  1  1  1  1  6 53]\n",
      "‚¨õ‚¨õ‚¨õ‚¨õ‚¨õ‚¨õ‚¨õ\n",
      "‚¨õ‚¨õ‚¨õ‚¨õ‚¨õ‚¨õ‚¨õ\n",
      "‚¨õ‚¨õ‚¨õüü°üî¥‚¨õ‚¨õ\n",
      "‚¨õ‚¨õ‚¨õüî¥üü°‚¨õ‚¨õ\n",
      "‚¨õ‚¨õ‚¨õüü°üî¥üü°‚¨õ\n",
      "‚¨õ‚¨õ‚¨õüî¥üü°üî¥üî¥\n",
      "1Ô∏è‚É£2Ô∏è‚É£3Ô∏è‚É£4Ô∏è‚É£5Ô∏è‚É£6Ô∏è‚É£7Ô∏è‚É£\n",
      "Turn:  -1\n",
      "Heuristics:\n",
      "Move probabilities: [0.044 0.051 0.048 0.028 0.19  0.172 0.466]\n",
      "Est. Score (1 = win, -1 = loss): -0.30703557\n",
      "On second thought:\n",
      "Move probabilities: [0. 0. 0. 0. 0. 0. 1.]\n",
      "Est. Score (1 = win, -1 = loss): 0.28276432\n",
      "# explored moves for each position:  [ 3  3  3  3 15 17 39]\n",
      "‚¨õ‚¨õ‚¨õ‚¨õ‚¨õ‚¨õ‚¨õ\n",
      "‚¨õ‚¨õ‚¨õ‚¨õ‚¨õ‚¨õ‚¨õ\n",
      "‚¨õ‚¨õ‚¨õüü°üî¥‚¨õ‚¨õ\n",
      "‚¨õ‚¨õ‚¨õüî¥üü°‚¨õ‚¨õ\n",
      "‚¨õ‚¨õ‚¨õüü°üî¥üü°üü°\n",
      "‚¨õ‚¨õ‚¨õüî¥üü°üî¥üî¥\n",
      "1Ô∏è‚É£2Ô∏è‚É£3Ô∏è‚É£4Ô∏è‚É£5Ô∏è‚É£6Ô∏è‚É£7Ô∏è‚É£\n",
      "Turn:  1\n",
      "Heuristics:\n",
      "Move probabilities: [0.037 0.119 0.108 0.039 0.057 0.293 0.346]\n",
      "Est. Score (1 = win, -1 = loss): 0.36416206\n",
      "On second thought:\n",
      "Move probabilities: [0.    0.    0.005 0.    0.    0.898 0.097]\n",
      "Est. Score (1 = win, -1 = loss): -0.5911828\n",
      "# explored moves for each position:  [ 2  8 12  3  2 20 16]\n",
      "‚¨õ‚¨õ‚¨õ‚¨õ‚¨õ‚¨õ‚¨õ\n",
      "‚¨õ‚¨õ‚¨õ‚¨õ‚¨õ‚¨õ‚¨õ\n",
      "‚¨õ‚¨õ‚¨õüü°üî¥‚¨õ‚¨õ\n",
      "‚¨õ‚¨õ‚¨õüî¥üü°‚¨õüî¥\n",
      "‚¨õ‚¨õ‚¨õüü°üî¥üü°üü°\n",
      "‚¨õ‚¨õ‚¨õüî¥üü°üî¥üî¥\n",
      "1Ô∏è‚É£2Ô∏è‚É£3Ô∏è‚É£4Ô∏è‚É£5Ô∏è‚É£6Ô∏è‚É£7Ô∏è‚É£\n",
      "Turn:  -1\n",
      "Heuristics:\n",
      "Move probabilities: [0.029 0.042 0.042 0.029 0.056 0.143 0.658]\n",
      "Est. Score (1 = win, -1 = loss): -0.49911058\n",
      "On second thought:\n",
      "Move probabilities: [0. 0. 0. 0. 0. 0. 1.]\n",
      "Est. Score (1 = win, -1 = loss): 0.64607656\n",
      "# explored moves for each position:  [ 2  2  1  2  4  9 63]\n",
      "‚¨õ‚¨õ‚¨õ‚¨õ‚¨õ‚¨õ‚¨õ\n",
      "‚¨õ‚¨õ‚¨õ‚¨õ‚¨õ‚¨õ‚¨õ\n",
      "‚¨õ‚¨õ‚¨õüü°üî¥‚¨õüü°\n",
      "‚¨õ‚¨õ‚¨õüî¥üü°‚¨õüî¥\n",
      "‚¨õ‚¨õ‚¨õüü°üî¥üü°üü°\n",
      "‚¨õ‚¨õ‚¨õüî¥üü°üî¥üî¥\n",
      "1Ô∏è‚É£2Ô∏è‚É£3Ô∏è‚É£4Ô∏è‚É£5Ô∏è‚É£6Ô∏è‚É£7Ô∏è‚É£\n",
      "Turn:  1\n",
      "Heuristics:\n",
      "Move probabilities: [0.042 0.13  0.132 0.071 0.065 0.408 0.152]\n",
      "Est. Score (1 = win, -1 = loss): 0.1870072\n",
      "On second thought:\n",
      "Move probabilities: [0.    0.    0.004 0.    0.    0.774 0.222]\n",
      "Est. Score (1 = win, -1 = loss): -0.035729155\n",
      "# explored moves for each position:  [ 2  8 10  7  4 17 15]\n",
      "‚¨õ‚¨õ‚¨õ‚¨õ‚¨õ‚¨õ‚¨õ\n",
      "‚¨õ‚¨õ‚¨õ‚¨õ‚¨õ‚¨õ‚¨õ\n",
      "‚¨õ‚¨õ‚¨õüü°üî¥‚¨õüü°\n",
      "‚¨õ‚¨õ‚¨õüî¥üü°üî¥üî¥\n",
      "‚¨õ‚¨õ‚¨õüü°üî¥üü°üü°\n",
      "‚¨õ‚¨õ‚¨õüî¥üü°üî¥üî¥\n",
      "1Ô∏è‚É£2Ô∏è‚É£3Ô∏è‚É£4Ô∏è‚É£5Ô∏è‚É£6Ô∏è‚É£7Ô∏è‚É£\n",
      "Turn:  -1\n",
      "Heuristics:\n",
      "Move probabilities: [0.045 0.094 0.134 0.038 0.095 0.321 0.272]\n",
      "Est. Score (1 = win, -1 = loss): -0.060358897\n",
      "On second thought:\n",
      "Move probabilities: [0. 0. 0. 0. 0. 1. 0.]\n",
      "Est. Score (1 = win, -1 = loss): 0.3955416\n",
      "# explored moves for each position:  [ 1  3  5  1  3 58 12]\n",
      "‚¨õ‚¨õ‚¨õ‚¨õ‚¨õ‚¨õ‚¨õ\n",
      "‚¨õ‚¨õ‚¨õ‚¨õ‚¨õ‚¨õ‚¨õ\n",
      "‚¨õ‚¨õ‚¨õüü°üî¥üü°üü°\n",
      "‚¨õ‚¨õ‚¨õüî¥üü°üî¥üî¥\n",
      "‚¨õ‚¨õ‚¨õüü°üî¥üü°üü°\n",
      "‚¨õ‚¨õ‚¨õüî¥üü°üî¥üî¥\n",
      "1Ô∏è‚É£2Ô∏è‚É£3Ô∏è‚É£4Ô∏è‚É£5Ô∏è‚É£6Ô∏è‚É£7Ô∏è‚É£\n",
      "Turn:  1\n",
      "Heuristics:\n",
      "Move probabilities: [0.032 0.143 0.318 0.04  0.071 0.068 0.329]\n",
      "Est. Score (1 = win, -1 = loss): -0.27365372\n",
      "On second thought:\n",
      "Move probabilities: [0.   0.   0.94 0.   0.   0.   0.06]\n",
      "Est. Score (1 = win, -1 = loss): -0.26856142\n",
      "# explored moves for each position:  [ 1  8 25  2  5  3 19]\n",
      "‚¨õ‚¨õ‚¨õ‚¨õ‚¨õ‚¨õ‚¨õ\n",
      "‚¨õ‚¨õ‚¨õ‚¨õ‚¨õ‚¨õüî¥\n",
      "‚¨õ‚¨õ‚¨õüü°üî¥üü°üü°\n",
      "‚¨õ‚¨õ‚¨õüî¥üü°üî¥üî¥\n",
      "‚¨õ‚¨õ‚¨õüü°üî¥üü°üü°\n",
      "‚¨õ‚¨õ‚¨õüî¥üü°üî¥üî¥\n",
      "1Ô∏è‚É£2Ô∏è‚É£3Ô∏è‚É£4Ô∏è‚É£5Ô∏è‚É£6Ô∏è‚É£7Ô∏è‚É£\n",
      "Turn:  -1\n",
      "Heuristics:\n",
      "Move probabilities: [0.058 0.093 0.431 0.05  0.126 0.071 0.171]\n",
      "Est. Score (1 = win, -1 = loss): 0.3498416\n",
      "On second thought:\n",
      "Move probabilities: [0. 0. 1. 0. 0. 0. 0.]\n",
      "Est. Score (1 = win, -1 = loss): -1\n",
      "# explored moves for each position:  [ 1  3 63  2  5  3  6]\n",
      "‚¨õ‚¨õ‚¨õ‚¨õ‚¨õ‚¨õ‚¨õ\n",
      "‚¨õ‚¨õ‚¨õ‚¨õ‚¨õ‚¨õüî¥\n",
      "‚¨õ‚¨õ‚¨õüü°üî¥üü°üü°\n",
      "‚¨õ‚¨õ‚¨õüî¥üü°üî¥üî¥\n",
      "‚¨õ‚¨õ‚¨õüü°üî¥üü°üü°\n",
      "‚¨õ‚¨õüü°üî¥üü°üî¥üî¥\n",
      "1Ô∏è‚É£2Ô∏è‚É£3Ô∏è‚É£4Ô∏è‚É£5Ô∏è‚É£6Ô∏è‚É£7Ô∏è‚É£\n",
      "GAME OVER!\n",
      "Yellow player wins!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ladder.play_match(agent,agent_2,render = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "825e18ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from memory.\n",
      "Loading model from memory.\n",
      "Loading model from memory.\n",
      "Loading model from memory.\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "No file or directory found at MachineTest/Epoch5.h5",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Input \u001b[1;32mIn [34]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m DEPTH \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m49\u001b[39m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m50\u001b[39m):\n\u001b[1;32m----> 4\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mmodels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mMachineTest/Epoch\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m.h5\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mcompile\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m     model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39moptimizers\u001b[38;5;241m.\u001b[39mAdam(\u001b[38;5;241m0.001\u001b[39m), loss\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mP_head\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary_crossentropy\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mQ_head\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmse\u001b[39m\u001b[38;5;124m\"\u001b[39m})\n\u001b[0;32m      6\u001b[0m     players\u001b[38;5;241m.\u001b[39mappend(A0(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mv3_Epoch_\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mstr\u001b[39m(i), \u001b[38;5;241m6\u001b[39m, DEPTH, model))\n",
      "File \u001b[1;32mC:\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mC:\\Python310\\lib\\site-packages\\keras\\saving\\save.py:226\u001b[0m, in \u001b[0;36mload_model\u001b[1;34m(filepath, custom_objects, compile, options)\u001b[0m\n\u001b[0;32m    224\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(filepath_str, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    225\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mio\u001b[38;5;241m.\u001b[39mgfile\u001b[38;5;241m.\u001b[39mexists(filepath_str):\n\u001b[1;32m--> 226\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(\n\u001b[0;32m    227\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo file or directory found at \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilepath_str\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    228\u001b[0m         )\n\u001b[0;32m    230\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mio\u001b[38;5;241m.\u001b[39mgfile\u001b[38;5;241m.\u001b[39misdir(filepath_str):\n\u001b[0;32m    231\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m saved_model_load\u001b[38;5;241m.\u001b[39mload(\n\u001b[0;32m    232\u001b[0m             filepath_str, \u001b[38;5;28mcompile\u001b[39m, options\n\u001b[0;32m    233\u001b[0m         )\n",
      "\u001b[1;31mOSError\u001b[0m: No file or directory found at MachineTest/Epoch5.h5"
     ]
    }
   ],
   "source": [
    "players = []\n",
    "DEPTH = 49\n",
    "for i in range(1,50):\n",
    "    model = models.load_model('MachineTest/Epoch'+str(i)+'.h5', compile = False)\n",
    "    model.compile(optimizer=optimizers.Adam(0.001), loss={'P_head': \"binary_crossentropy\", 'Q_head': \"mse\"})\n",
    "    players.append(A0('v3_Epoch_'+str(i), 6, DEPTH, model))\n",
    "        #A0_nodepth('v3_Epoch_'+str(i),6, model))\n",
    "class RandomPlayer(object):\n",
    "    def __init__(self, name = \"Random\"):\n",
    "        self.name = name\n",
    "    def norm_probs(self, probs, tops):\n",
    "        probs *= (tops != 6)\n",
    "        probs *= (1 / np.sum(probs))\n",
    "        return probs\n",
    "    def make_move(self, game, turn):\n",
    "        probs = np.ones(7) / 7\n",
    "        probs = self.norm_probs(probs, game.tops)\n",
    "        return np.random.choice(range(0, 7), p = probs)\n",
    "players.append(RandomPlayer())\n",
    "#model = models.load_model(\"Remote/v3_Boosted.h5\")\n",
    "#players.append(A0('v3_Boosted', 6, DEPTH, model))\n",
    "    #A0_nodepth('V3_Boosted',6, model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "043307b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ladder = Ladder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52178ed4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                     | 72/100 [1:08:27<51:15, 109.85s/it]"
     ]
    }
   ],
   "source": [
    "results = ladder.play_tournament(players, K = 400, NUM_MATCHES = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1acd4a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "results['v3_Epoch_16'] = results['v3_Boosted'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1c959b45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'v3_Epoch_1': 1212.6838712164285,\n",
       " 'v3_Epoch_2': 1266.2220095196726,\n",
       " 'v3_Epoch_3': 1453.2119974993707,\n",
       " 'v3_Epoch_4': 1392.4627390012124,\n",
       " 'v3_Epoch_5': 1419.18194347816,\n",
       " 'v3_Epoch_6': 1385.6627525367412,\n",
       " 'v3_Epoch_7': 1473.695297896697,\n",
       " 'v3_Epoch_8': 1394.9221299563724,\n",
       " 'v3_Epoch_9': 1587.3747259999286,\n",
       " 'v3_Epoch_10': 1464.2491137566194,\n",
       " 'v3_Epoch_11': 1573.9663995963197,\n",
       " 'v3_Epoch_12': 1565.000113322334,\n",
       " 'v3_Epoch_13': 1440.5257503284129,\n",
       " 'v3_Epoch_14': 1423.943716716693,\n",
       " 'v3_Epoch_15': 1585.616491367458,\n",
       " 'Random': 1000.0000000000001,\n",
       " 'v3_Boosted': 1595.8570463493093,\n",
       " 'v3_Epoch_16': 1595.8570463493093}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "fe97f527",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_results = {'v3_Epoch_1': 1071.560978669389,\n",
    " 'v3_Epoch_2': 1158.3984801667766,\n",
    " 'v3_Epoch_3': 1172.136020116286,\n",
    " 'v3_Epoch_4': 1241.724793345752,\n",
    " 'v3_Epoch_5': 1322.5102766599723,\n",
    " 'v3_Epoch_6': 1295.6323713595716,\n",
    " 'v3_Epoch_7': 1420.2875324110491,\n",
    " 'v3_Epoch_8': 1400.9242170523535,\n",
    " 'v3_Epoch_9': 1476.8973340235748,\n",
    " 'v3_Epoch_10': 1448.0126204771827,\n",
    " 'v3_Epoch_11': 1425.1173682856129,\n",
    " 'v3_Epoch_12': 1425.9147777621524,\n",
    " 'v3_Epoch_13': 1463.8800688419155,\n",
    " 'v3_Epoch_14': 1363.9386623192977,\n",
    " 'v3_Epoch_15': 1421.9380051389985,\n",
    " 'Random': 1000.0,\n",
    " 'V3_Boosted': 1448.4124823091965,\n",
    " 'v3_Epoch_16': 1448.4124823091965}\n",
    "\n",
    "depth_7_results = {'v3_Epoch_1': 1212.6838712164285,\n",
    " 'v3_Epoch_2': 1266.2220095196726,\n",
    " 'v3_Epoch_3': 1453.2119974993707,\n",
    " 'v3_Epoch_4': 1392.4627390012124,\n",
    " 'v3_Epoch_5': 1419.18194347816,\n",
    " 'v3_Epoch_6': 1385.6627525367412,\n",
    " 'v3_Epoch_7': 1473.695297896697,\n",
    " 'v3_Epoch_8': 1394.9221299563724,\n",
    " 'v3_Epoch_9': 1587.3747259999286,\n",
    " 'v3_Epoch_10': 1464.2491137566194,\n",
    " 'v3_Epoch_11': 1573.9663995963197,\n",
    " 'v3_Epoch_12': 1565.000113322334,\n",
    " 'v3_Epoch_13': 1440.5257503284129,\n",
    " 'v3_Epoch_14': 1423.943716716693,\n",
    " 'v3_Epoch_15': 1585.616491367458,\n",
    " 'Random': 1000.0000000000001,\n",
    " 'v3_Boosted': 1595.8570463493093,\n",
    " 'v3_Epoch_16': 1595.8570463493093}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6145d654",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\seaborn\\_decorators.py:36: FutureWarning: Pass the following variables as keyword args: x, y. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\seaborn\\_decorators.py:36: FutureWarning: Pass the following variables as keyword args: x, y. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\seaborn\\_decorators.py:36: FutureWarning: Pass the following variables as keyword args: x, y. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'ELO')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.lineplot(range(1,17), [baseline_results['v3_Epoch_'+str(i)] for i in range(1, 17)], label = \"Depth 0 (no lookahead)\")\n",
    "sns.lineplot(range(1,17), [depth_7_results['v3_Epoch_'+str(i)] for i in range(1, 17)], label = \"Depth 7 (one-step lookahead)\")\n",
    "sns.lineplot(range(1,17), 1000, label = \"Random agent\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"ELO\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03ebcb77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def play_match(agent, challenger):\n",
    "    agent_turn = (random.randint(0, 1) * 2) - 1\n",
    "    game = Connect4Game()\n",
    "    turn = 1\n",
    "    while (game.result() == None):\n",
    "        for i in range(agent.n_simulations):\n",
    "            starttime = time.time()\n",
    "\n",
    "            copy_game = Connect4Game()\n",
    "            # Pass by copy (we don't want the internal MCTS to modify the outer game)\n",
    "            copy_game.board = game.board.copy()\n",
    "            copy_game.tops = game.tops.copy()\n",
    "            copy_game.moves_played = game.moves_played # integer\n",
    "            if turn == agent_turn: agent.MCTS(copy_game, turn)\n",
    "            else: challenger.MCTS(copy_game, turn)\n",
    "\n",
    "        s = (game.board * turn).tobytes()\n",
    "        \n",
    "        if turn == agent_turn:\n",
    "            move_qualities = np.array([agent.N[s][a] if game.tops[a] != 6 else 0 for a in range(7)])\n",
    "\n",
    "            agent.visited.clear() # Reset tree\n",
    "            # game.render() DEBUG\n",
    "            agent.N.clear()\n",
    "            agent.Q.clear()\n",
    "            agent.P.clear()\n",
    "\n",
    "        else:\n",
    "            move_qualities = np.array([challenger.N[s][a] if game.tops[a] != 6 else 0 for a in range(7)])\n",
    "\n",
    "            challenger.visited.clear() # Reset tree\n",
    "            # game.render() DEBUG\n",
    "            challenger.N.clear()\n",
    "            challenger.Q.clear()\n",
    "            challenger.P.clear()\n",
    "\n",
    "        probs = move_qualities / (np.sum(move_qualities) + 0.00001)\n",
    "        probs *= (1/np.sum(probs))\n",
    "\n",
    "        action = np.random.choice(range(0, 7), p = probs)\n",
    "        game.play(action, turn)\n",
    "\n",
    "        turn *= -1\n",
    "    if game.result() == agent_turn:\n",
    "        return (1,0)\n",
    "    elif game.result() == -agent_turn:\n",
    "        return (0,1)\n",
    "    else:\n",
    "        return (0.5,0.5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
